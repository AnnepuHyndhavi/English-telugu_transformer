{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4E1CZ39SskCj"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "lC5pMaKAwHdV",
        "outputId": "1f0e42b1-69d3-4dbc-c904-fb7bf52a63ae"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-104790fb-34dc-45eb-852f-95a3d7426140\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>english</th>\n",
              "      <th>telugu</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Hello</td>\n",
              "      <td>హలో</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Are you good?</td>\n",
              "      <td>మీరు బాగున్నారా?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I am happy</td>\n",
              "      <td>నేను సంతోషంగా ఉన్నాను</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>how are you?</td>\n",
              "      <td>మీరు ఎలా ఉన్నారు?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I am good</td>\n",
              "      <td>నేను భాగున్నాను</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-104790fb-34dc-45eb-852f-95a3d7426140')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-104790fb-34dc-45eb-852f-95a3d7426140 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-104790fb-34dc-45eb-852f-95a3d7426140');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "         english                 telugu\n",
              "0          Hello                    హలో\n",
              "1  Are you good?       మీరు బాగున్నారా?\n",
              "2     I am happy  నేను సంతోషంగా ఉన్నాను\n",
              "3   how are you?      మీరు ఎలా ఉన్నారు?\n",
              "4      I am good        నేను భాగున్నాను"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_full = pd.read_excel('/content/drive/MyDrive/Datasets/AI Project/language_data.xlsx')\n",
        "df_full.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hanK3624PvYj"
      },
      "outputs": [],
      "source": [
        "df_full['word_count_en'] = df_full['english'].str.split().str.len()\n",
        "df_full['word_count_te'] = df_full['telugu'].str.split().str.len()\n",
        "df = df_full[(df_full['word_count_en'] <= 20) & (df_full['word_count_te'] <= 20)]\n",
        "df = df.drop(columns=['word_count_en', 'word_count_te'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "TSAzV7TERzjJ",
        "outputId": "48c2055b-dba3-49f3-8d71-69b94b683140"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-1de54b3c-56ad-44b8-ac96-c9204b01effd\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>english</th>\n",
              "      <th>telugu</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Hello</td>\n",
              "      <td>హలో</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Are you good?</td>\n",
              "      <td>మీరు బాగున్నారా?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I am happy</td>\n",
              "      <td>నేను సంతోషంగా ఉన్నాను</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>how are you?</td>\n",
              "      <td>మీరు ఎలా ఉన్నారు?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I am good</td>\n",
              "      <td>నేను భాగున్నాను</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1de54b3c-56ad-44b8-ac96-c9204b01effd')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1de54b3c-56ad-44b8-ac96-c9204b01effd button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1de54b3c-56ad-44b8-ac96-c9204b01effd');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "         english                 telugu\n",
              "0          Hello                    హలో\n",
              "1  Are you good?       మీరు బాగున్నారా?\n",
              "2     I am happy  నేను సంతోషంగా ఉన్నాను\n",
              "3   how are you?      మీరు ఎలా ఉన్నారు?\n",
              "4      I am good        నేను భాగున్నాను"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UnM4R3juw1pK",
        "outputId": "09db55ac-1e53-47be-f61e-9445b0552783"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "20\n",
            "బాక్టీరియల్ జీవితం కొన్నిసార్లు వృక్షజాలం, [71] [72] లో చేర్చబడుతుంది మరియు కొన్ని వర్గీకరణలు మొక్కల వృక్షజాలం నుండి విడిగా బ్యాక్టీరియా వృక్షజాలం అనే పదాన్ని ఉపయోగిస్తాయి.\n"
          ]
        }
      ],
      "source": [
        "en_vals = df['telugu'].values\n",
        "max_len = 0\n",
        "word = \"\"\n",
        "for val in en_vals:\n",
        "  val_len = len(val.split())\n",
        "  if val_len > max_len:\n",
        "    max_len = val_len\n",
        "    word = val\n",
        "\n",
        "print(max_len)\n",
        "print(word)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o0a_6rW01F6u"
      },
      "outputs": [],
      "source": [
        "text_pairs = []\n",
        "for index, row in df.iterrows():\n",
        "  english, telugu = row['english'], row['telugu']\n",
        "  # print(english, telugu) \n",
        "  telugu = \"[start] \" + telugu + \" [end]\"\n",
        "  text_pairs.append((english, telugu))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mpWXHQOb2Ddy",
        "outputId": "971f2e6c-20fe-4ecf-c8e5-ece424f5b6a1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "9331"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(text_pairs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vcn00HPM3l2Z",
        "outputId": "286e238b-d39b-4730-f0f0-7fd31648cd51"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "('Joe made the sugar cookies; Susan decorated them.', '[start] జో చక్కెర కుకీలను తయారు చేశాడు; సుసాన్ వారిని అలంకరించాడు. [end]')\n",
            "6531 1399\n"
          ]
        }
      ],
      "source": [
        "print(random.choice(text_pairs))\n",
        "\n",
        "random.shuffle(text_pairs)\n",
        "\n",
        "num_train_samples = int(0.7 * len(text_pairs))\n",
        "num_val_samples = int(0.15 * len(text_pairs))\n",
        "print(num_train_samples, num_val_samples)\n",
        "train_pairs = text_pairs[:num_train_samples]\n",
        "val_pairs = text_pairs[num_train_samples:num_train_samples + num_val_samples]\n",
        "test_pairs = text_pairs[num_train_samples + num_val_samples:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gT4j_zq-w1l8"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import string\n",
        "import re\n",
        "from tensorflow.keras import layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "XbiwL9qB4lBr",
        "outputId": "90f1eed4-d9e1-478a-9099-16d877073833"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'!\"#$%&\\'()*+,-./:;<=>?@\\\\^_`{|}~'"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "strip_chars = string.punctuation\n",
        "strip_chars = strip_chars.replace(\"[\", \"\")\n",
        "strip_chars = strip_chars.replace(\"]\", \"\")\n",
        "strip_chars"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6-Tvrt-Fw1i0"
      },
      "outputs": [],
      "source": [
        "\n",
        "def custom_standardization(input_string):\n",
        "    lowercase = tf.strings.lower(input_string)\n",
        "    return tf.strings.regex_replace(\n",
        "        lowercase, f\"[{re.escape(strip_chars)}]\", \"\")\n",
        "\n",
        "vocab_size = 15000\n",
        "sequence_length = 20\n",
        "\n",
        "source_vectorization = layers.TextVectorization(\n",
        "    max_tokens=vocab_size,\n",
        "    output_mode=\"int\",\n",
        "    output_sequence_length=sequence_length,\n",
        "    standardize=custom_standardization,\n",
        ")\n",
        "target_vectorization = layers.TextVectorization(\n",
        "    max_tokens=vocab_size,\n",
        "    output_mode=\"int\",\n",
        "    output_sequence_length=sequence_length + 1,\n",
        "    standardize=custom_standardization,\n",
        ")\n",
        "train_english_texts = [pair[0] for pair in train_pairs]\n",
        "train_telugu_texts = [pair[1] for pair in train_pairs]\n",
        "source_vectorization.adapt(train_english_texts)\n",
        "target_vectorization.adapt(train_telugu_texts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XVzI7fVyimyL",
        "outputId": "1e21a433-6105-4c44-cd03-e70e174939ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "7412\n",
            "10802\n"
          ]
        }
      ],
      "source": [
        "print(len(source_vectorization.get_vocabulary()))\n",
        "print(len(target_vectorization.get_vocabulary()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MDUoE7bxizeH",
        "outputId": "b4b4ad53-313d-478f-a211-6082de06909d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['', '[UNK]', 'the', 'a', 'and', 'to', 'of', 'i', 'in', 'he', 'my', 'with', 'was', 'she', 'on']\n",
            "['', '[UNK]', '[start]', '[end]', 'మరియు', 'నేను', 'అతను', 'ఆమె', 'నా', 'ఒక']\n"
          ]
        }
      ],
      "source": [
        "print(source_vectorization.get_vocabulary()[:15])\n",
        "print(target_vectorization.get_vocabulary()[:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hXddQcNh6hyT",
        "outputId": "2bb0d50d-6e56-4b30-c6ad-3f43410b8be8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "He is good at eating pickles and telling women about his emotional problems.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(20,), dtype=int64, numpy=\n",
              "array([   9,   15,   93,   22,  123, 1288,    4,  350, 1095,   30,   19,\n",
              "        428,  514,    0,    0,    0,    0,    0,    0,    0])>"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "samp = random.choice(train_english_texts)\n",
        "print(samp)\n",
        "source_vectorization(samp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W-B1zTzRw1f5"
      },
      "outputs": [],
      "source": [
        "# Preparing dataset\n",
        "batch_size = 64\n",
        "\n",
        "def format_dataset(eng, tel):\n",
        "    eng = source_vectorization(eng)\n",
        "    tel = target_vectorization(tel)\n",
        "    return ({\n",
        "        \"english\": eng,\n",
        "        \"telugu\": tel[:, :-1],\n",
        "    }, tel[:, 1:])\n",
        "\n",
        "def make_dataset(pairs):\n",
        "    eng_texts, tel_texts = zip(*pairs)\n",
        "    eng_texts = list(eng_texts)\n",
        "    tel_texts = list(tel_texts)\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((eng_texts, tel_texts))\n",
        "    dataset = dataset.batch(batch_size)\n",
        "    dataset = dataset.map(format_dataset, num_parallel_calls=4)\n",
        "    return dataset.shuffle(2048).prefetch(16).cache()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KRzTqa3c5UoX"
      },
      "outputs": [],
      "source": [
        "train_ds = make_dataset(train_pairs)\n",
        "val_ds = make_dataset(val_pairs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Do9OWzf5Ul7",
        "outputId": "eb2ba752-d49f-4a24-bbb7-b87d29936321"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "english shape: (64, 20)\n",
            "telugu shape: (64, 20)\n",
            "target shape: (64, 20)\n"
          ]
        }
      ],
      "source": [
        "for inputs, targets in train_ds.take(1):\n",
        "    print(f\"english shape: {inputs['english'].shape}\")\n",
        "    print(f\"telugu shape: {inputs['telugu'].shape}\")\n",
        "    print(f\"target shape: {targets.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LYtgM4I2iNEC",
        "outputId": "c16fb9ae-6b29-4dd8-eba1-ac0d38b042b1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[  7 260  10 234   8   2  87   4 114   2 393  14  10 220   0   0   0   0\n",
            "   0   0], shape=(20,), dtype=int64)\n",
            "tf.Tensor(\n",
            "[   2    5    8  343  177 1048    4    8  321   47  102 5878    3    0\n",
            "    0    0    0    0    0    0], shape=(20,), dtype=int64)\n",
            "tf.Tensor(\n",
            "[   5    8  343  177 1048    4    8  321   47  102 5878    3    0    0\n",
            "    0    0    0    0    0    0], shape=(20,), dtype=int64)\n"
          ]
        }
      ],
      "source": [
        "print(inputs['english'][0])\n",
        "print(inputs['telugu'][0])\n",
        "print(targets[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Xz6mTzx7ZLx"
      },
      "outputs": [],
      "source": [
        "class TransformerEncoder(layers.Layer):\n",
        "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.embed_dim = embed_dim\n",
        "        self.dense_dim = dense_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.attention = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.dense_layers = tf.keras.Sequential(\n",
        "            [layers.Dense(dense_dim, activation=\"relu\"),\n",
        "             layers.Dense(embed_dim),]\n",
        "        )\n",
        "        self.layernorm_1 = layers.LayerNormalization()\n",
        "        self.layernorm_2 = layers.LayerNormalization()\n",
        "\n",
        "    def call(self, inputs, mask=None):\n",
        "        if mask is not None:\n",
        "            mask = mask[:, tf.newaxis, :]\n",
        "        attention_output = self.attention(\n",
        "            inputs, inputs, attention_mask=mask)\n",
        "        proj_input = self.layernorm_1(inputs + attention_output)\n",
        "        proj_output = self.dense_layers(proj_input)\n",
        "        return self.layernorm_2(proj_input + proj_output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hu7zNFB75UjY"
      },
      "outputs": [],
      "source": [
        "class TransformerDecoder(layers.Layer):\n",
        "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.embed_dim = embed_dim\n",
        "        self.dense_dim = dense_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.attention_1 = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.attention_2 = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.dense_layers = tf.keras.Sequential(\n",
        "            [layers.Dense(dense_dim, activation=\"relu\"),\n",
        "             layers.Dense(embed_dim),]\n",
        "        )\n",
        "        self.layernorm_1 = layers.LayerNormalization()\n",
        "        self.layernorm_2 = layers.LayerNormalization()\n",
        "        self.layernorm_3 = layers.LayerNormalization()\n",
        "        self.supports_masking = True\n",
        "\n",
        "    def masked_attention(self, inputs):\n",
        "        input_shape = tf.shape(inputs)\n",
        "        batch_size, sequence_length = input_shape[0], input_shape[1]\n",
        "        i = tf.range(sequence_length)[:, tf.newaxis]\n",
        "        j = tf.range(sequence_length)\n",
        "        mask = tf.cast(i >= j, dtype=\"int32\")\n",
        "        mask = tf.reshape(mask, (1, input_shape[1], input_shape[1]))\n",
        "        mult = tf.concat(\n",
        "            [tf.expand_dims(batch_size, -1),\n",
        "             tf.constant([1, 1], dtype=tf.int32)], axis=0)\n",
        "        return tf.tile(mask, mult)\n",
        "\n",
        "    def call(self, inputs, encoder_outputs, mask=None):\n",
        "        causal_mask = self.masked_attention(inputs)\n",
        "        attention_output_1 = self.attention_1(\n",
        "            query=inputs,\n",
        "            value=inputs,\n",
        "            key=inputs,\n",
        "            attention_mask=causal_mask)\n",
        "        attention_output_1 = self.layernorm_1(inputs + attention_output_1)\n",
        "        attention_output_2 = self.attention_2(\n",
        "            query=attention_output_1,\n",
        "            value=encoder_outputs,\n",
        "            key=encoder_outputs\n",
        "        )\n",
        "        attention_output_2 = self.layernorm_2(\n",
        "            attention_output_1 + attention_output_2)\n",
        "        proj_output = self.dense_layers(attention_output_2)\n",
        "        return self.layernorm_3(attention_output_2 + proj_output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V1OvKwJm5mHn"
      },
      "outputs": [],
      "source": [
        "class PositionalEmbedding(layers.Layer):\n",
        "    def __init__(self, sequence_length, input_dim, output_dim, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.token_embeddings = layers.Embedding(\n",
        "            input_dim=input_dim, output_dim=output_dim)\n",
        "        self.position_embeddings = layers.Embedding(\n",
        "            input_dim=sequence_length, output_dim=output_dim)\n",
        "        self.sequence_length = sequence_length\n",
        "        self.input_dim = input_dim\n",
        "        self.output_dim = output_dim\n",
        "\n",
        "    def call(self, inputs):\n",
        "        length = tf.shape(inputs)[-1]\n",
        "        positions = tf.range(start=0, limit=length, delta=1)\n",
        "        embedded_tokens = self.token_embeddings(inputs)\n",
        "        embedded_positions = self.position_embeddings(positions)\n",
        "        return embedded_tokens + embedded_positions\n",
        "\n",
        "    def compute_mask(self, inputs, mask=None):\n",
        "        return tf.math.not_equal(inputs, 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8OLuZM8s5mEq"
      },
      "outputs": [],
      "source": [
        "embed_dim = 512\n",
        "dense_dim = 2048\n",
        "num_heads = 6\n",
        "\n",
        "encoder_inputs = tf.keras.Input(shape=(None,), dtype=\"int64\", name=\"english\")\n",
        "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(encoder_inputs)\n",
        "encoder_outputs = TransformerEncoder(embed_dim, dense_dim, num_heads)(x)\n",
        "\n",
        "decoder_inputs = tf.keras.Input(shape=(None,), dtype=\"int64\", name=\"telugu\")\n",
        "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(decoder_inputs)\n",
        "x = TransformerDecoder(embed_dim, dense_dim, num_heads)(x, encoder_outputs)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "decoder_outputs = layers.Dense(vocab_size, activation=\"softmax\")(x)\n",
        "transformer = tf.keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rtqc3GaR734v",
        "outputId": "c9595b2a-58ea-4875-8b16-6268451b2874"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " english (InputLayer)           [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " telugu (InputLayer)            [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " positional_embedding (Position  (None, None, 256)   3845120     ['english[0][0]']                \n",
            " alEmbedding)                                                                                     \n",
            "                                                                                                  \n",
            " positional_embedding_1 (Positi  (None, None, 256)   3845120     ['telugu[0][0]']                 \n",
            " onalEmbedding)                                                                                   \n",
            "                                                                                                  \n",
            " transformer_encoder (Transform  (None, None, 256)   3154432     ['positional_embedding[0][0]']   \n",
            " erEncoder)                                                                                       \n",
            "                                                                                                  \n",
            " transformer_decoder (Transform  (None, None, 256)   4206848     ['positional_embedding_1[0][0]', \n",
            " erDecoder)                                                       'transformer_encoder[0][0]']    \n",
            "                                                                                                  \n",
            " dropout (Dropout)              (None, None, 256)    0           ['transformer_decoder[0][0]']    \n",
            "                                                                                                  \n",
            " dense_4 (Dense)                (None, None, 15000)  3855000     ['dropout[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 18,906,520\n",
            "Trainable params: 18,906,520\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "transformer.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rnu6ZUS25mCJ",
        "outputId": "9dfa68f8-f9f6-4893-d218-ab12010edc39"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "103/103 [==============================] - 46s 295ms/step - loss: 6.8353 - accuracy: 0.2198 - val_loss: 5.9717 - val_accuracy: 0.2595\n",
            "Epoch 2/30\n",
            "103/103 [==============================] - 7s 65ms/step - loss: 5.1427 - accuracy: 0.3386 - val_loss: 4.9285 - val_accuracy: 0.4035\n",
            "Epoch 3/30\n",
            "103/103 [==============================] - 6s 59ms/step - loss: 3.7628 - accuracy: 0.4866 - val_loss: 4.1852 - val_accuracy: 0.4848\n",
            "Epoch 4/30\n",
            "103/103 [==============================] - 7s 65ms/step - loss: 2.7706 - accuracy: 0.5843 - val_loss: 3.7866 - val_accuracy: 0.5343\n",
            "Epoch 5/30\n",
            "103/103 [==============================] - 6s 60ms/step - loss: 2.0312 - accuracy: 0.6752 - val_loss: 3.5382 - val_accuracy: 0.5757\n",
            "Epoch 6/30\n",
            "103/103 [==============================] - 7s 68ms/step - loss: 1.4511 - accuracy: 0.7426 - val_loss: 3.4038 - val_accuracy: 0.6047\n",
            "Epoch 7/30\n",
            "103/103 [==============================] - 6s 59ms/step - loss: 1.0189 - accuracy: 0.8030 - val_loss: 3.3373 - val_accuracy: 0.6233\n",
            "Epoch 8/30\n",
            "103/103 [==============================] - 6s 61ms/step - loss: 0.7031 - accuracy: 0.8583 - val_loss: 3.3349 - val_accuracy: 0.6307\n",
            "Epoch 9/30\n",
            "103/103 [==============================] - 6s 60ms/step - loss: 0.4890 - accuracy: 0.8986 - val_loss: 3.4294 - val_accuracy: 0.6345\n",
            "Epoch 10/30\n",
            "103/103 [==============================] - 7s 68ms/step - loss: 0.3454 - accuracy: 0.9279 - val_loss: 3.4134 - val_accuracy: 0.6420\n",
            "Epoch 11/30\n",
            "103/103 [==============================] - 6s 60ms/step - loss: 0.2549 - accuracy: 0.9467 - val_loss: 3.4686 - val_accuracy: 0.6397\n",
            "Epoch 12/30\n",
            "103/103 [==============================] - 6s 62ms/step - loss: 0.1970 - accuracy: 0.9583 - val_loss: 3.4860 - val_accuracy: 0.6478\n",
            "Epoch 13/30\n",
            "103/103 [==============================] - 6s 60ms/step - loss: 0.1516 - accuracy: 0.9675 - val_loss: 3.5615 - val_accuracy: 0.6479\n",
            "Epoch 14/30\n",
            "103/103 [==============================] - 6s 62ms/step - loss: 0.1226 - accuracy: 0.9738 - val_loss: 3.6048 - val_accuracy: 0.6498\n",
            "Epoch 15/30\n",
            "103/103 [==============================] - 6s 60ms/step - loss: 0.0998 - accuracy: 0.9788 - val_loss: 3.6485 - val_accuracy: 0.6531\n",
            "Epoch 16/30\n",
            "103/103 [==============================] - 6s 62ms/step - loss: 0.0860 - accuracy: 0.9812 - val_loss: 3.6562 - val_accuracy: 0.6532\n",
            "Epoch 17/30\n",
            "103/103 [==============================] - 6s 61ms/step - loss: 0.0852 - accuracy: 0.9824 - val_loss: 3.7353 - val_accuracy: 0.6534\n",
            "Epoch 18/30\n",
            "103/103 [==============================] - 6s 63ms/step - loss: 0.0789 - accuracy: 0.9834 - val_loss: 3.7864 - val_accuracy: 0.6538\n",
            "Epoch 19/30\n",
            "103/103 [==============================] - 6s 60ms/step - loss: 0.0742 - accuracy: 0.9845 - val_loss: 3.8176 - val_accuracy: 0.6510\n",
            "Epoch 20/30\n",
            "103/103 [==============================] - 7s 68ms/step - loss: 0.0711 - accuracy: 0.9852 - val_loss: 3.8194 - val_accuracy: 0.6556\n",
            "Epoch 21/30\n",
            "103/103 [==============================] - 6s 61ms/step - loss: 0.0789 - accuracy: 0.9831 - val_loss: 3.8293 - val_accuracy: 0.6495\n",
            "Epoch 22/30\n",
            "103/103 [==============================] - 7s 67ms/step - loss: 0.0727 - accuracy: 0.9844 - val_loss: 3.9204 - val_accuracy: 0.6482\n",
            "Epoch 23/30\n",
            "103/103 [==============================] - 6s 61ms/step - loss: 0.0729 - accuracy: 0.9839 - val_loss: 3.9299 - val_accuracy: 0.6506\n",
            "Epoch 24/30\n",
            "103/103 [==============================] - 7s 67ms/step - loss: 0.0796 - accuracy: 0.9826 - val_loss: 3.9686 - val_accuracy: 0.6492\n",
            "Epoch 25/30\n",
            "103/103 [==============================] - 6s 61ms/step - loss: 0.0768 - accuracy: 0.9823 - val_loss: 3.9744 - val_accuracy: 0.6472\n",
            "Epoch 26/30\n",
            "103/103 [==============================] - 7s 63ms/step - loss: 0.0723 - accuracy: 0.9839 - val_loss: 4.0147 - val_accuracy: 0.6470\n",
            "Epoch 27/30\n",
            "103/103 [==============================] - 6s 61ms/step - loss: 0.0683 - accuracy: 0.9845 - val_loss: 4.0736 - val_accuracy: 0.6478\n",
            "Epoch 28/30\n",
            "103/103 [==============================] - 6s 63ms/step - loss: 0.0647 - accuracy: 0.9856 - val_loss: 4.0999 - val_accuracy: 0.6471\n",
            "Epoch 29/30\n",
            "103/103 [==============================] - 7s 68ms/step - loss: 0.0656 - accuracy: 0.9854 - val_loss: 4.0961 - val_accuracy: 0.6492\n",
            "Epoch 30/30\n",
            "103/103 [==============================] - 6s 62ms/step - loss: 0.0732 - accuracy: 0.9829 - val_loss: 4.1636 - val_accuracy: 0.6478\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f8e100dcd00>"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "transformer.compile(\n",
        "    optimizer=\"adam\",\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"])\n",
        "transformer.fit(train_ds, epochs=30, validation_data=val_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "atPff_XU7w3E"
      },
      "outputs": [],
      "source": [
        "tel_vocab = target_vectorization.get_vocabulary()\n",
        "tel_index_lookup = dict(zip(range(len(tel_vocab)), tel_vocab))\n",
        "max_decoded_sentence_length = sequence_length\n",
        "\n",
        "def decode_sequence(input_sentence, transformer_model):\n",
        "    tokenized_input_sentence = source_vectorization([input_sentence])\n",
        "    decoded_sentence = \"[start]\"\n",
        "    for i in range(max_decoded_sentence_length):\n",
        "        tokenized_target_sentence = target_vectorization(\n",
        "            [decoded_sentence])[:, :-1]\n",
        "        predictions = transformer_model(\n",
        "            [tokenized_input_sentence, tokenized_target_sentence])\n",
        "        sampled_token_index = np.argmax(predictions[0, i, :])\n",
        "        sampled_token = tel_index_lookup[sampled_token_index]\n",
        "        decoded_sentence += \" \" + sampled_token\n",
        "        if sampled_token == \"[end]\":\n",
        "            break\n",
        "    return decoded_sentence\n",
        "\n",
        "test_eng_texts = [pair[0] for pair in test_pairs]\n",
        "test_tel_texts = [pair[1] for pair in test_pairs]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1QjFGTsunyyW",
        "outputId": "0e7d8138-52f0-4cdd-fe2b-4dee2f36127c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-\n",
            "Input: They went on a hike in the mountains.\n",
            "Prediction: [start] వారు ప్రకృతిని ఆస్వాదించడానికి పర్వతాలలో పాదయాత్రకు వెళుతున్నాను [end]\n",
            "Actual: [start] వారు పర్వతాలలో పాదయాత్రకు వెళ్ళారు. [end]\n",
            "-\n",
            "Input: She did her best to help him.\n",
            "Prediction: [start] అతనికి సహాయం చేయడానికి ఆమె తన వంతు కృషి చేసింది [end]\n",
            "Actual: [start] అతనికి సహాయం చేయడానికి ఆమె తన వంతు కృషి చేసింది. [end]\n",
            "-\n",
            "Input: The mysterious diary records the voice.\n",
            "Prediction: [start] మర్మమైన డైరీ వాయిస్ రికార్డ్ చేస్తుంది [end]\n",
            "Actual: [start] మర్మమైన డైరీ వాయిస్ రికార్డ్ చేస్తుంది. [end]\n",
            "-\n",
            "Input: He felt a sense of accomplishment after completing a challenging project.\n",
            "Prediction: [start] అతను సవాలు చేసే వ్యాయామం పూర్తి చేయడంతో అతను సాఫల్య భావాన్ని అనుభవించాడు [end]\n",
            "Actual: [start] అతను సవాలు చేసే ప్రాజెక్టును పూర్తి చేసిన తర్వాత సాధించిన భావాన్ని అనుభవించాడు. [end]\n"
          ]
        }
      ],
      "source": [
        "actual = []\n",
        "predictions = []\n",
        "for i in range(1, 5):\n",
        "    # input_sentence = random.choice(test_eng_texts)\n",
        "    r = random.randint(0, len(test_eng_texts))\n",
        "    input_sentence = test_eng_texts[r]\n",
        "    actual_sentence = test_tel_texts[r]\n",
        "    actual.append(actual_sentence.split()[1:-1])\n",
        "    print(\"-\")\n",
        "    print(\"Input:\", input_sentence)\n",
        "    predicted_sentence = decode_sequence(input_sentence, transformer)\n",
        "    predictions.append(predicted_sentence.split()[1:-1])\n",
        "    print(\"Prediction:\", predicted_sentence)\n",
        "    print(\"Actual:\", actual_sentence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ifgx3wCzoWLP",
        "outputId": "f5d937bc-dcac-47cf-8f79-46ac646d5e82"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1\n",
            "9\n"
          ]
        }
      ],
      "source": [
        "print(len([actual[0]]))\n",
        "print(len(predictions[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ImcpphCeoB9D",
        "outputId": "817f825f-71bc-47d3-ef0a-3ca1681208cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "8.38826642100846e-155\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
            "The hypothesis contains 0 counts of 3-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
            "The hypothesis contains 0 counts of 4-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n"
          ]
        }
      ],
      "source": [
        "from nltk.translate.bleu_score import corpus_bleu, sentence_bleu\n",
        "score = sentence_bleu([actual[0]], predictions[0])\n",
        "print(score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Epj4VlT8m2t",
        "outputId": "9e226b1b-8056-408c-9d10-86889b80109f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[start] హలో మీరు ఈ రోజు ఎలా [end]\n"
          ]
        }
      ],
      "source": [
        "text_input = \"Hello, how are you today?\"\n",
        "predicted_output = decode_sequence(text_input, transformer)\n",
        "print(predicted_output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sXtquKG2mcTG"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A6SfYbGym34n"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y5xVORKNm5Yk"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
